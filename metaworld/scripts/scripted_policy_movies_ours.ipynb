{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ykai/anaconda3/envs/metaGarage/lib/python3.9/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import functools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tests.metaworld.envs.mujoco.sawyer_xyz.test_scripted_policies import ALL_ENVS, test_cases_latest_nonoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def trajectory_generator(env, policy, act_noise_pct, res=(640, 480), camera='corner'):\n",
    "    action_space_ptp = env.action_space.high - env.action_space.low\n",
    "\n",
    "    env.reset()\n",
    "    env.reset_model()\n",
    "    o = env.reset()\n",
    "\n",
    "    for _ in range(env.max_path_length):\n",
    "        a = policy.get_action(o)\n",
    "        a = np.random.normal(a, act_noise_pct * action_space_ptp)\n",
    "\n",
    "        o, r, done, info = env.step(a)\n",
    "        # Camera is one of ['corner', 'topview', 'behindGripper', 'gripperPOV']\n",
    "        # print(np.shape(env.sim.render(*res, mode='offscreen', camera_name=camera)[:,:,::-1]))\n",
    "        yield r, done, info, env.sim.render(*res, mode='offscreen', camera_name=camera)[:,:,::-1]\n",
    "\n",
    "# def writer_for(tag, fps, res):\n",
    "#     if not os.path.exists('movies_my'):\n",
    "#         os.mkdir('movies_my')\n",
    "#     return cv2.VideoWriter(\n",
    "#         f'movies_my/{tag}.avi',\n",
    "#         cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "#         fps,\n",
    "#         res\n",
    "#     )\n",
    "\n",
    "def write_for_img(tag, img):\n",
    "    if not os.path.exists('movies_my'):\n",
    "        os.mkdir('movies_my')\n",
    "    name = f'movies_my/{tag}.png'\n",
    "    return cv2.imwrite(name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so:/usr/lib/nvidia/libGL.so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia\n",
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia-510\n",
    "!export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ykai/anaconda3/envs/metaGarage/lib/python3.9/site-packages/gym/spaces/box.py:84: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "/home/ykai/anaconda3/envs/metaGarage/lib/python3.9/site-packages/metaworld/policies/policy.py:41: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]\n",
      "  warnings.warn('Constant(s) may be too high. Environments clip response to [-1, 1]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 GPUs for rendering. Using device 0.\n",
      "(1080, 1920, 3)\n",
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "resolution = (1920, 1080)\n",
    "camera = 'topview' # one of ['corner', 'topview', 'behindGripper', 'gripperPOV']\n",
    "camera = ['topview', 'corner', 'corner2', 'corner3', 'behindGripper', 'gripperPOV']\n",
    "my_camera = ['my_corner3', 'my_topview1']\n",
    "camera = my_camera\n",
    "flip=True # if True, flips output image 180 degrees\n",
    "\n",
    "config = [\n",
    "    # env, action noise pct, cycles, quit on success\n",
    "    ('assembly-v2', np.zeros(4), 1, True),\n",
    "]\n",
    "for camera in camera:\n",
    "    if camera in ['corner', 'corner2', 'corner3', 'gripperPOV', 'my_corner3']:\n",
    "        flip = False\n",
    "    else:\n",
    "        flip = True\n",
    "    for env, noise, cycles, quit_on_success in config:\n",
    "        tag = env + '-noise-' + np.array2string(noise, precision=2, separator=',', suppress_small=True)\\\n",
    "            + '-cycles-'+ str(cycles) +'-camera-'+ camera\n",
    "\n",
    "        policy = functools.reduce(lambda a,b : a if a[0] == env else b, test_cases_latest_nonoise)[1]\n",
    "        env = ALL_ENVS[env]()\n",
    "        env._partially_observable = False\n",
    "        env._freeze_rand_vec = False\n",
    "        env._set_task_called = True\n",
    "\n",
    "        # writer = writer_for(tag, env.metadata['video.frames_per_second'], resolution)\n",
    "        # for _ in range(cycles):\n",
    "        #     for r, done, info, img in trajectory_generator(env, policy, noise, resolution, camera):\n",
    "        #         if flip: img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        #         writer.write(img)\n",
    "        #         if quit_on_success and info['success']:\n",
    "        #             break\n",
    "        # writer.release()\n",
    "        \n",
    "        for _ in range(cycles):\n",
    "            for r, done, info, img in trajectory_generator(env, policy, noise, resolution, camera):\n",
    "                print(np.shape(img))\n",
    "                if flip: img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "                write_for_img(tag, img)\n",
    "                break\n",
    "            \n",
    "                if quit_on_success and info['success']:\n",
    "                    break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_corner3 camera에러가 나올경우, pip install --user .로 현 경로의 metaworld 재설치."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(egg_file)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39m# if egg_file:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=16'>17</a>\u001b[0m \u001b[39m#     os.remove(egg_file[0])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=18'>19</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(egg_file[\u001b[39m0\u001b[39;49m], \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=19'>20</a>\u001b[0m     data \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ykai/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts/scripted_policy_movies_ours.ipynb#ch0000006?line=20'>21</a>\u001b[0m     \u001b[39mprint\u001b[39m(data)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def get_egg_file(module_name):\n",
    "    def f(packages):\n",
    "        return glob.glob(\n",
    "            os.path.join(os.path.dirname(os.path.dirname(sys.executable)),\n",
    "                         'lib', 'python*', packages, module_name + '.egg-link'))\n",
    "\n",
    "    return f('site-packages') or f('dist-packages')\n",
    "\n",
    "\n",
    "egg_file = get_egg_file('metaworld')\n",
    "print(egg_file)\n",
    "# if egg_file:\n",
    "#     os.remove(egg_file[0])\n",
    "\n",
    "with open(egg_file[0], \"r\") as file:\n",
    "    data = file.read()\n",
    "    print(data)\n",
    "    # file.write(\"Hello~ \\n\")\n",
    "    # file.write(\"World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_trajectory_generator(env, policy, act_noise_pct, res=(640, 480), camera='corner', depth = True):\n",
    "    action_space_ptp = env.action_space.high - env.action_space.low\n",
    "    print(\"E1\")\n",
    "    env.reset()\n",
    "    env.reset_model()\n",
    "    o = env.reset()\n",
    "\n",
    "    for _ in range(env.max_path_length):\n",
    "        a = policy.get_action(o)\n",
    "        a = np.random.normal(a, act_noise_pct * action_space_ptp)\n",
    "\n",
    "        o, r, done, info = env.step(a)\n",
    "        # Camera is one of ['corner', 'topview', 'behindGripper', 'gripperPOV']\n",
    "        # print(np.shape(env.sim.render(*res, mode='offscreen', camera_name=camera)[:,:,::-1]))\n",
    "        img, d = env.sim.render(*res, mode='offscreen', camera_name=camera,depth = depth)\n",
    "        # print(depth)\n",
    "        print(\"E\")\n",
    "        yield r, done, info, img, d\n",
    "        \n",
    "def write_for_img(tag, img):\n",
    "    if not os.path.exists('movies_my'):\n",
    "        os.mkdir('movies_my')\n",
    "    name = f'movies_my/{tag}.png'\n",
    "    return cv2.imwrite(name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def bright_img(tag, img):\n",
    "    if not os.path.exists('movies_my'):\n",
    "        os.mkdir('movies_my')\n",
    "    name = f'movies_my/{tag}.png'\n",
    "    src = img\n",
    "    val = 100\n",
    "    array = np.full(src.shape, (val, val, val), dtype=np.uint8)\n",
    "\n",
    "    add = cv2.add(src, array)\n",
    "    return cv2.imwrite(name, add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1\n",
      "E\n",
      "[[0.9997777  0.99977785 0.9997781  ... 0.9997956  0.9997954  0.99979514]\n",
      " [0.99977785 0.9997781  0.9997783  ... 0.9997958  0.99979556 0.9997953 ]\n",
      " [0.99977803 0.9997783  0.99977845 ... 0.999796   0.99979573 0.9997955 ]\n",
      " ...\n",
      " [0.9902057  0.9902049  0.9902041  ... 0.9886916  0.98869085 0.9886901 ]\n",
      " [0.9902004  0.9901996  0.99019885 ... 0.9886864  0.98868555 0.9886848 ]\n",
      " [0.99019516 0.9901944  0.99019355 ... 0.9886811  0.9886803  0.9886795 ]]\n",
      "(1080, 1920)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [7 7 7 ... 8 8 8]\n",
      " [7 7 7 ... 8 8 8]\n",
      " [7 7 7 ... 8 8 8]]\n",
      "E1\n",
      "E\n",
      "[[0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]\n",
      " [0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]\n",
      " [0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]\n",
      " ...\n",
      " [0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]\n",
      " [0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]\n",
      " [0.99442875 0.99442875 0.99442875 ... 0.99442875 0.99442875 0.99442875]]\n",
      "(1080, 1920)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "resolution = (1920, 1080)\n",
    "camera = 'topview' # one of ['corner', 'topview', 'behindGripper', 'gripperPOV']\n",
    "camera = ['topview', 'corner', 'corner2', 'corner3', 'behindGripper', 'gripperPOV']\n",
    "my_camera = ['my_corner3', 'my_topview1']\n",
    "camera = my_camera\n",
    "flip=True # if True, flips output image 180 degrees\n",
    "\n",
    "config = [\n",
    "    # env, action noise pct, cycles, quit on success\n",
    "    ('assembly-v2', np.zeros(4), 1, True),\n",
    "]\n",
    "\n",
    "for camera in camera:\n",
    "    if camera in ['corner', 'corner2', 'corner3', 'gripperPOV', 'my_corner3']:\n",
    "        flip = False\n",
    "    else:\n",
    "        flip = True\n",
    "    for env, noise, cycles, quit_on_success in config:\n",
    "        tag = env + '-noise-' + np.array2string(noise, precision=2, separator=',', suppress_small=True)\\\n",
    "            + '-cycles-'+ str(cycles) +'-camera-'+ camera\n",
    "\n",
    "        policy = functools.reduce(lambda a,b : a if a[0] == env else b, test_cases_latest_nonoise)[1]\n",
    "        env = ALL_ENVS[env]()\n",
    "        env._partially_observable = False\n",
    "        env._freeze_rand_vec = False\n",
    "        env._set_task_called = True\n",
    "        for _ in range(cycles):\n",
    "            for r, done, info, img, depth in my_trajectory_generator(env, policy, noise, resolution, camera, depth = True):\n",
    "\n",
    "                if flip: img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                write_for_img(tag, img)\n",
    "                print(depth)\n",
    "                # d = d[:, np.newaxis] \n",
    "                # print(img.shape)\n",
    "                # print(d.shape)\n",
    "                # print(d*255)\n",
    "                depth = (np.max(depth)-depth) / (np.max(depth) - np.min(depth))\n",
    "                # depth = (depth-np.min(depth)) / (np.max(depth) - np.min(depth))\n",
    "                depth = np.asarray(depth * 15, dtype=np.uint8)\n",
    "                print(np.shape(depth))\n",
    "                print(depth)\n",
    "                write_for_img(tag+'_depth', depth)\n",
    "                break\n",
    "            \n",
    "                if quit_on_success and info['success']:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:, :, 0], img[:, :, 2] = img[:, :, 2], img[:, :, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "name = f'movies_my/linemod_depth2.png'\n",
    "\n",
    "img = cv2.imread(name)\n",
    "print(np.max(img))\n",
    "print(np.min(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "gray_img = cv2.imread(name)\n",
    "print(gray_img.dtype)\n",
    "print(np.shape(gray_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49e4eb5cbff0ec5c28376266370c54afeb1300aa523691c90c3088f8e0cd18b0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('metaGarage')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
