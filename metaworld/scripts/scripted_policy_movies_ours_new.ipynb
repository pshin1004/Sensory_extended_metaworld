{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Quick Start\n",
    "- conda create -n {name} python=3.9\n",
    "- conda activate {name}\n",
    "- cd {metaworld root}\n",
    "- pip install .\n",
    "- conda install -c anaconda ipykernel\n",
    "- conda install -c conda-forge opencv\n",
    "- conda install -c anaconda pytest\n",
    "- conda install -c anaconda scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preventing some error message\n",
    "import gym\n",
    "gym.logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import functools\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tests.metaworld.envs.mujoco.sawyer_xyz.test_scripted_policies import ALL_ENVS, test_cases_latest_nonoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "!LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so:/usr/lib/nvidia/libGL.so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia\n",
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia-510\n",
    "!export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libGLEW.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ssd_2/ssd2048/papers/Sensory_extended_metaworld/metaworld/scripts'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_trajectory_generator(env, policy, act_noise_pct, res=(640, 480), camera='corner1', depth = True):\n",
    "    action_space_ptp = env.action_space.high - env.action_space.low\n",
    "    env.reset()\n",
    "    env.reset_model()\n",
    "    o = env.reset()\n",
    "    \n",
    "    for _ in range(env.max_path_length):\n",
    "        a = policy.get_action(o)\n",
    "        a = np.random.normal(a, act_noise_pct * action_space_ptp)\n",
    "\n",
    "        o, r, done, info = env.step(a)\n",
    "        # Camera is one of ['corner', 'topview', 'behindGripper', ...]\n",
    "        # pose is like [x,y,z], z direction vector is normal to table surface.\n",
    "        # obj_pos, hand_pos, goal, obj_pos2, obj_quat2 =  env.obj_init_pos, env.hand_init_pos, env.goal, \\\n",
    "        # env.data.site_xpos[env.model.site_name2id('RoundNut-8')], env.sim.data.get_body_xquat('RoundNut')\n",
    "        # obj_angle, obj_pos, hand_pos, goal, obj_pos2, obj_quat2 =  env._get_pos_objects() , env._get_obs_dict(), env.hand_init_pos, env.goal, \\\n",
    "        # env.data.site_xpos[env.model.site_name2id('RoundNut-8')], env.sim.data.get_body_xquat('RoundNut')\n",
    "        # peg_pos = env._target_pos - np.array([0., 0., 0.05])\n",
    "        \n",
    "        img, d = env.sim.render(*res, mode='offscreen', camera_name=camera, depth = depth)\n",
    "        # print(depth)\n",
    "        #\"obj_angle\": obj_angle, \n",
    "        yield r, done, info, img, d, {}\n",
    "        # , {\"obj_pos\": obj_pos, \"hand_pos\": hand_pos, \"goal\": goal, \"obj_pos2\": obj_pos2, \"obj_quat2\": obj_quat2, \"peg_pos\": peg_pos}\n",
    "        \n",
    "def write_for_img(tag, img):\n",
    "    if not os.path.exists('latentfusion_inputs'):\n",
    "        os.mkdir('latentfusion_inputs')\n",
    "    name = f'latentfusion_inputs/{tag}.png'\n",
    "    return cv2.imwrite(name, img)\n",
    "\n",
    "def write_log_text(tag, pose, written):\n",
    "    if not written:\n",
    "        import time\n",
    "        timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        name = f'latentfusion_inputs/{tag}.txt'\n",
    "        with open(name, \"a\") as file:\n",
    "            file.write(timestr+\":\\t\")\n",
    "            for key in pose:\n",
    "                file.write(key+\":\"+str(pose[key])+\"\\t\")\n",
    "            file.write(\"\\n\")\n",
    "            file.close()\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ykai/anaconda3/envs/Testaa/lib/python3.9/site-packages/metaworld/policies/policy.py:41: UserWarning: Constant(s) may be too high. Environments clip response to [-1, 1]\n",
      "  warnings.warn('Constant(s) may be too high. Environments clip response to [-1, 1]')\n"
     ]
    }
   ],
   "source": [
    "resolution = (640, 480)\n",
    "camera = ['topview', 'corner1', 'corner2', 'corner3', 'behindGripper']\n",
    "flip=True # if True, flips output image 180 degrees\n",
    "\n",
    "config = [\n",
    "    # env, action noise pct, cycles, quit on success\n",
    "    ('button-press-topdown-v2', np.zeros(4), 1, True),\n",
    "]\n",
    "pose_log_written = False\n",
    "for camera in camera:\n",
    "    if camera in ['corner1', 'corner2', 'corner3']:\n",
    "        flip = False\n",
    "    else:\n",
    "        flip = True\n",
    "    for env, noise, cycles, quit_on_success in config:\n",
    "        tag = env + '-noise-' + np.array2string(noise, precision=2, separator=',', suppress_small=True)\\\n",
    "            + '-cycles-'+ str(cycles) +'-camera-'+ camera\n",
    "\n",
    "        policy = functools.reduce(lambda a,b : a if a[0] == env else b, test_cases_latest_nonoise)[1]\n",
    "        env = ALL_ENVS[env]()\n",
    "        env._partially_observable = False\n",
    "        env._freeze_rand_vec = False\n",
    "        env._set_task_called = True\n",
    "        for _ in range(cycles):\n",
    "            for r, done, info, img, depth, pose in my_trajectory_generator(env, policy, noise, resolution, camera, depth = True):\n",
    "                if flip: img = cv2.rotate(img, cv2.ROTATE_180); depth = cv2.rotate(depth, cv2.ROTATE_180)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                write_for_img(tag, img)\n",
    "                \n",
    "                # print(depth)\n",
    "                depth = (np.max(depth)-depth) / (np.max(depth) - np.min(depth))\n",
    "                # depth = (depth-np.min(depth)) / (np.max(depth) - np.min(depth))\n",
    "                depth = np.asarray(depth * 15, dtype=np.uint8)\n",
    "                # print(np.shape(depth))\n",
    "                # print(depth)\n",
    "                write_for_img(tag+'_depth', depth)\n",
    "                \n",
    "                # print(pose)\n",
    "                pose_log_written = write_log_text(\"pose\", pose, pose_log_written)\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is example log of \"latentfusion_inputs/pose.txt\".\n",
    "- 20220602-000011:\tobj_angle:0.3\tobj_pos:[0.         0.60000002 0.02      ]\thand_pos:[0.  0.6 0.2]\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c863dab3e473e6a95fb3bd2f60bce5515eaebce20b5d05d4566631180f0114b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Testaa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
